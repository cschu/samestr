#!/usr/bin/env python3
"""SameStr: Shared Strains Identification in Metagenomic Samples."""


from sys import stderr
from os.path import basename, dirname, realpath, isdir, isfile
from os import environ, makedirs
import logging
import logging.config

from samestr.utils.utilities import list_group_by_basename, collect_input_files
from samestr.utils.ooSubprocess import serialize, parallelize_async
from samestr.utils.file_mapping import spread_args_by_input_files, get_uniform_extension, \
    set_output_structure

from samestr.convert import sam2bam, concatenate_gene_files, bam2freq
from samestr.extract import ref2freq
from samestr.filter import filter_freqs
from samestr.merge import freq2freqs
from samestr.stats import aln2stats
from samestr.compare import compare
from samestr.summarize import summarize
from samestr.db import generate_db

from samestr.utils.parse_args import read_params


SAMESTR_DIR = dirname(realpath(__file__))
CONVERT_DIR = SAMESTR_DIR + '/convert/'
UTILS_DIR = SAMESTR_DIR + '/utils/'
environ['PATH'] += ':' + UTILS_DIR + ':' + CONVERT_DIR


def samestr(input_args):
    """Main function for SAMESTR."""
    accepted_extensions_dict = {
        'db': ['.fasta', '.fa', '.fna', '.fasta.bz2', '.fa.bz2', '.fna.bz2'],
        'convert': ['.sam', '.sam.bz2', '.bam'],
        'extract': ['.fasta', '.fa', '.fna', '.fasta.gz', '.fa.gz', '.fna.gz'],
        'merge': ['.npy', '.npy.gz', '.npz'],
        'filter': ['.npy', '.npy.gz', '.npz'],
        'stats': ['.npy', '.npy.gz', '.npz'],
        'compare': ['.npy', '.npy.gz', '.npz'],
        'summarize': ['']
    }

    ## preprocess input/output files & extensions and map to commands
    ####
    accepted_extensions = accepted_extensions_dict[input_args['command']]
    if input_args['command'] == 'db':
        input_args['input_extension'] = get_uniform_extension(
            [input_args['markers_fasta']], accepted_extensions)
        
        if input_args['db_source'] == 'MetaPhlAn' and 'markers_pkl' not in input_args:
            LOG.error('`markers-pkl` not provided. Required when using MetaPhlAn as the source database.')
            exit(0)

    elif input_args['command'] not in ('summarize'):
        input_args['input_extension'] = get_uniform_extension(
            input_args['input_files'], accepted_extensions)

        # Count input files
        file_count = len(input_args['input_files'])
        LOG.debug('Number of input files: %s', file_count)

    # check make output dir
    if not isdir(input_args['output_dir']):
        makedirs(input_args['output_dir'])

    ## process individual commands
    ####
    if input_args['command'] == 'db':

        # expand and generate db from markers/pkl files
        generate_db(input_args)

    elif input_args['command'] == 'extract':
        cmd_args = serialize(ref2freq, [input_args])

    elif input_args['command'] == 'convert':
        # input_args['input_files'], input_args['input_extension'] = collect_input_files(
        #     input_args['input_dir'],
        #     accepted_extensions,
        #     recursive=input_args["recursive_input"]
        # )
        
        # TODO: is this still needed?
        input_args['input_files'] = list_group_by_basename(
            input_args['input_files'],
            cut_name_endings=[input_args['input_extension']])

        # Spread args over files/file-pairs, Set output names and check/make their dir
        input_args['input_sequence_type'] = 'single'
        cmd_args = spread_args_by_input_files(input_args)
        cmd_args = set_output_structure(cmd_args)

        # Run: convert
        cmd_args = parallelize_async(concatenate_gene_files, cmd_args,
                                 input_args['nprocs'])
        
        cmd_args = parallelize_async(sam2bam, cmd_args, input_args['nprocs'])        
        cmd_args = parallelize_async(bam2freq, cmd_args, input_args['nprocs'])

    elif input_args['command'] == 'merge':

        clade_file_dict = {}

        # group input files by clade
        for file_path in input_args['input_files']:
            file = basename(file_path)
            clade = file.split('.')[0]

            # append list if file has been merged before
            sample_names = file_path.replace(
                input_args['input_extension'], '.names.txt')
            if isfile(sample_names):
                with open(sample_names, 'r', encoding="utf8") as s_n:
                    sample = s_n.read().strip().split('\n')
            else:
                sample = file.split(input_args['input_extension'])[
                    0].replace(f'{clade}.', '')

            # skip if not in selected clade
            if input_args['clade']:
                if clade not in input_args['clade']:
                    continue

            if clade not in clade_file_dict:
                clade_file_dict[clade] = [[sample, file_path]]
            else:
                clade_file_dict[clade] += [[sample, file_path]]

        cmd_args = []
        for idx, clade in enumerate(clade_file_dict.keys()):
            cmd_args.append({})
            cmd_args[idx]['clade'] = clade
            cmd_args[idx]['input_files'] = clade_file_dict[clade]
            cmd_args[idx]['output_dir'] = input_args['output_dir']

        cmd_args = parallelize_async(freq2freqs, cmd_args, input_args['nprocs'])

    elif input_args['command'] in ['filter', 'stats', 'compare']:

        # For each clade: group freqs with resp names
        freqs = {}
        for i_f in input_args['input_files']:
            clade = basename(i_f).split(input_args['input_extension'])[0]
            freqs[clade] = [i_f]

        for i_n in input_args['input_names']:
            clade = basename(i_n).split('.names.txt')[0]
            if clade not in freqs:
                LOG.warning('Skipping %s. Found name file '
                            'but no SNV profile.', clade)
            else:
                freqs[clade] += [i_n]

        for clade, freq in list(freqs.items()):
            if len(freq) != 2:
                LOG.warning('Skipping [%s]. Found SNV profile '
                            'but no name file: %s' % (clade, ', '.join(freq)))
                freqs.pop(clade)
            if 'clade' in input_args and input_args['clade'] is not None:
                if clade not in input_args['clade']:
                    freqs.pop(clade)

        # attach sample selection file
        if 'samples_select' in input_args:
            for i_s in input_args['samples_select']:
                clade = basename(i_s).split('.select.txt')[0]
                if clade not in freqs:
                    LOG.warning('Skipping [%s]. Found selection file '
                                'but no SNV profile: %s' % (clade, ', '.join(freq)))
                    freqs[clade] += [i_s]

        for clade, freq in list(freqs.items()):
            if len(freq) > 3:
                LOG.warning('Skipping %s. Found more than one '
                            'sample selection file: %s' % (clade, ', '.join(freq)))
                freqs.pop(clade)
            elif len(freq) == 2:
                freq += [None]
            elif len(freq) != 3:
                LOG.error('Unexpected number of files (%s) for [%s]: %s' % (clade, ', '.join(freq)))
                exit(0)

        # Spread args over clades
        cmd_args = []
        for idx, (clade, (input_file, input_name,
                            input_select)) in enumerate(freqs.items()):
            cmd_args.append({})
            cmd_args[idx]['input_file'] = input_file
            cmd_args[idx]['input_name'] = input_name
            cmd_args[idx]['input_select'] = input_select
            cmd_args[idx]['clade'] = clade

            for arg in input_args:
                if arg in [
                    'input_files', 'input_names', 'input_select', 'clade'
                ]:
                    continue
                cmd_args[idx][arg] = input_args[arg]

        if input_args['command'] == 'filter':
            LOG.info('Filtering files: %s', len(freqs))

            # Run: filter
            cmd_args = parallelize_async(filter_freqs, cmd_args, input_args['nprocs'])

        elif input_args['command'] == 'stats':
            LOG.info('Gathering statistics: %s', len(freqs))

            # Run: stats
            cmd_args = parallelize_async(aln2stats, cmd_args, input_args['nprocs'])

        elif input_args['command'] == 'compare':
            LOG.info('Comparing alignments: %s', len(freqs))

            # Run: compare
            cmd_args = parallelize_async(compare, cmd_args, input_args['nprocs'])

    elif input_args['command'] == 'summarize':
        cmd_args = serialize(summarize, [input_args])

citations = {
'Text' :  
"""
Podlesny D, Arze C, Dörner E, Verma S, Dutta S, Walter J, Fricke WF. 
Metagenomic strain detection with SameStr: 
identification of a persisting core gut microbiota transferable by fecal transplantation. 
Microbiome. 2022 Mar 25;10(1):53. doi: 10.1186/s40168-022-01251-w. 
PMID: 35337386; PMCID: PMC8951724.
""",
'BibTex' : 
"""
@article{podlesny2022metagenomic,
title={Metagenomic strain detection with SameStr: identification of a persisting core gut microbiota transferable by fecal transplantation},
author={Podlesny, Daniel and Arze, Cesar and D{\"o}rner, Elisabeth and Verma, Sandeep and Dutta, Sudhir and Walter, Jens and Fricke, W Florian},
journal={Microbiome},
volume={10},
number={1},
pages={1--15},
year={2022},
publisher={BioMed Central}
}
""",
'RIS' : 
"""
TY  - JOUR
AU  - Podlesny, Daniel
AU  - Arze, Cesar
AU  - Dörner, Elisabeth
AU  - Verma, Sandeep
AU  - Dutta, Sudhir
AU  - Walter, Jens
AU  - Fricke, W. Florian
PY  - 2022
DA  - 2022/03/25
TI  - Metagenomic strain detection with SameStr: identification of a persisting core gut microbiota transferable by fecal transplantation
JO  - Microbiome
SP  - 53
VL  - 10
IS  - 1
AB  - The understanding of how microbiomes assemble, function, and evolve requires metagenomic tools that can resolve microbiota compositions at the strain level. However, the identification and tracking of microbial strains in fecal metagenomes is challenging and available tools variably classify subspecies lineages, which affects their applicability to infer microbial persistence and transfer.
SN  - 2049-2618
UR  - https://doi.org/10.1186/s40168-022-01251-w
DO  - 10.1186/s40168-022-01251-w
ID  - Podlesny2022
ER  - 
""",
'DOI' : 'https://doi.org/10.1186/s40168-022-01251-w',
'Endnote' : 
"""
%0 Journal Article
%T Metagenomic strain detection with SameStr: identification of a persisting core gut microbiota transferable by fecal transplantation
%A Podlesny, Daniel
%A Arze, Cesar
%A Dörner, Elisabeth
%A Verma, Sandeep
%A Dutta, Sudhir
%A Walter, Jens
%A Fricke, W Florian
%J Microbiome
%V 10
%N 1
%P 1-15
%@ 2049-2618
%D 2022
%I BioMed Central          
"""
}

if __name__ == "__main__":
    args = read_params()

    if args['citation'] is not None:
        print(citations[args['citation']])
        exit(0)

    logging.basicConfig(
    level=getattr(logging, args['verbosity']),
    stream=stderr,
    format='%(asctime)s | %(levelname)s | %(name)s | %(funcName)s | %(lineno)d | %(message)s'
    )
    LOG = logging.getLogger(__name__)

    samestr(args)
