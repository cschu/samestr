#!/usr/bin/env python3
"""SameStr: Shared Strains Identification in Metagenomic Samples."""


from sys import stderr
from os.path import basename, dirname, realpath, isdir, isfile
from os import environ, makedirs
import logging
import logging.config

from samestr.utils.utilities import list_group_by_basename, collect_input_files
from samestr.utils.ooSubprocess import serialize, parallelize_async
from samestr.utils.file_mapping import spread_args_by_input_files, get_uniform_extension, \
    set_output_structure

from samestr.convert import sam2bam, concatenate_gene_files, bam2freq
from samestr.extract import ref2freq
from samestr.filter import filter_freqs
from samestr.merge import freq2freqs
from samestr.stats import aln2stats
from samestr.compare import compare
from samestr.summarize import summarize
from samestr.db import mp2db

from samestr.utils.parse_args import read_params
from samestr.utils.citations import citations


SAMESTR_DIR = dirname(realpath(__file__))
CONVERT_DIR = SAMESTR_DIR + '/convert/'
UTILS_DIR = SAMESTR_DIR + '/utils/'
environ['PATH'] += ':' + UTILS_DIR + ':' + CONVERT_DIR


def samestr(input_args):
    """Main function for SAMESTR."""
    accepted_extensions_dict = {
        'convert': ['.sam', '.sam.bz2'],
        'db': ['.fasta', '.fa', '.fna', '.fasta.bz2', '.fa.bz2', '.fna.bz2'],
        'extract': ['.fasta', '.fa', '.fna', '.fasta.gz', '.fa.gz', '.fna.gz'],
        'merge': ['.npy', '.npy.gz', '.npz'],
        'filter': ['.npy', '.npy.gz', '.npz'],
        'stats': ['.npy', '.npy.gz', '.npz'],
        'compare': ['.npy', '.npy.gz', '.npz'],
        'summarize': ['']
    }

    ## preprocess input/output files & extensions and map to commands
    ####
    accepted_extensions = accepted_extensions_dict[input_args['command']]
    if input_args['command'] == 'db':
        input_args['input_extension'] = get_uniform_extension(
            [input_args['mpa_markers']], accepted_extensions)

    elif input_args['command'] not in ('summarize', 'convert'):
        input_args['input_extension'] = get_uniform_extension(
            input_args['input_files'], accepted_extensions)

        # Count input files
        file_count = len(input_args['input_files'])
        LOG.debug('Number of input files: %s', file_count)

    # check make output dir
    if not isdir(input_args['output_dir']):
        makedirs(input_args['output_dir'])

    ## process individual commands
    ####
    if input_args['command'] == 'convert':
        input_args['input_files'], input_args['input_extension'] = collect_input_files(
            input_args['input_dir'],
            accepted_extensions,
            recursive=input_args["recursive_input"]
        )
        
        # input_args['input_files'] = list_group_by_basename(
        #     input_args['input_files'],
        #     cut_name_endings=[input_args['input_extension']])

        # Spread args over files/file-pairs, Set output names and check/make their dir
        input_args['input_sequence_type'] = 'single'
        cmd_args = spread_args_by_input_files(input_args)
        cmd_args = set_output_structure(cmd_args)

        # Run: convert
        cmd_args = parallelize_async(sam2bam, cmd_args, input_args['nprocs'])
        cmd_args = parallelize_async(concatenate_gene_files, cmd_args,
                                 input_args['nprocs'])
        cmd_args = parallelize_async(bam2freq, cmd_args, input_args['nprocs'])

    elif input_args['command'] == 'db':

        # expand and generate db from metaphlan markers/pkl files
        mp2db(input_args)

    elif input_args['command'] == 'merge':

        species_file_dict = {}

        # group input files by species
        for file_path in input_args['input_files']:
            file = basename(file_path)
            species = file.split('.')[0]

            # append list if file has been merged before
            sample_names = file_path.replace(
                input_args['input_extension'], '.names.txt')
            if isfile(sample_names):
                with open(sample_names, 'r', encoding="utf8") as s_n:
                    sample = s_n.read().strip().split('\n')
            else:
                sample = file.split(input_args['input_extension'])[
                    0].replace(f'{species}.', '')

            # skip if not in selected species
            if input_args['species']:
                if species not in input_args['species']:
                    continue

            if species not in species_file_dict:
                species_file_dict[species] = [[sample, file_path]]
            else:
                species_file_dict[species] += [[sample, file_path]]

        cmd_args = []
        for idx, species in enumerate(species_file_dict.keys()):
            cmd_args.append({})
            cmd_args[idx]['species'] = species
            cmd_args[idx]['input_files'] = species_file_dict[species]
            cmd_args[idx]['output_dir'] = input_args['output_dir']

        cmd_args = parallelize_async(freq2freqs, cmd_args, input_args['nprocs'])

    elif input_args['command'] in ['filter', 'stats', 'compare']:

        # For each species: group freqs with resp names
        freqs = {}
        for i_f in input_args['input_files']:
            species = basename(i_f).split(input_args['input_extension'])[0]
            freqs[species] = [i_f]

        for i_n in input_args['input_names']:
            species = basename(i_n).split('.names.txt')[0]
            if species not in freqs:
                LOG.warning('Skipping %s. Found name file '
                            'but no SNV profile.', species)
            else:
                freqs[species] += [i_n]

        for species, freq in list(freqs.items()):
            if len(freq) != 2:
                LOG.warning('Skipping %s. Found SNV profile '
                            'but no name file.', species)
                freqs.pop(species)
            if 'species' in input_args and input_args['species'] is not None:
                if species not in input_args['species']:
                    freqs.pop(species)

        # attach sample selection file
        if 'samples_select' in input_args:
            for i_s in input_args['samples_select']:
                species = basename(i_s).split('.select.txt')[0]
                if species not in freqs:
                    LOG.warning('Skipping %s. Found selection file '
                                'but no SNV profile.', species)
                else:
                    freqs[species] += [i_s]

        for species, freq in list(freqs.items()):
            if len(freq) > 3:
                LOG.warning('Skipping %s. Found more than one '
                            'sample selection file.', species)
                freqs.pop(species)
            elif len(freq) == 2:
                freq += [None]
            elif len(freq) != 3:
                LOG.error('Unexpected number of files (%s): %s.', len(freq), species)
                exit(0)

        # Spread args over species
        cmd_args = []
        for idx, (species, (input_file, input_name,
                            input_select)) in enumerate(freqs.items()):
            cmd_args.append({})
            cmd_args[idx]['input_file'] = input_file
            cmd_args[idx]['input_name'] = input_name
            cmd_args[idx]['input_select'] = input_select
            cmd_args[idx]['species'] = species

            for arg in input_args:
                if arg in [
                    'input_files', 'input_names', 'input_select', 'species'
                ]:
                    continue
                cmd_args[idx][arg] = input_args[arg]

        if input_args['command'] == 'filter':
            LOG.info('Filtering files: %s', len(freqs))

            # Run: filter
            cmd_args = parallelize_async(filter_freqs, cmd_args, input_args['nprocs'])

        elif input_args['command'] == 'stats':
            LOG.info('Gathering statistics: %s', len(freqs))

            # Run: stats
            cmd_args = parallelize_async(aln2stats, cmd_args, input_args['nprocs'])

        elif input_args['command'] == 'compare':
            LOG.info('Comparing alignments: %s', len(freqs))

            # Run: compare
            cmd_args = parallelize_async(compare, cmd_args, input_args['nprocs'])

    elif input_args['command'] == 'summarize':
        cmd_args = serialize(summarize, [input_args])

    elif input_args['command'] == 'extract':
        cmd_args = serialize(ref2freq, [input_args])



if __name__ == "__main__":
    args = read_params()

    if args['citation'] is not None:
        print(citations[args['citation']])
        exit(0)

    logging.basicConfig(
    level=getattr(logging, args['verbosity']),
    stream=stderr,
    format='%(asctime)s | %(levelname)s | %(name)s | %(funcName)s | %(lineno)d | %(message)s'
    )
    LOG = logging.getLogger(__name__)

    samestr(args)
