#!/usr/bin/env python3
"""SameStr: Shared Strains Identification in Metagenomic Samples."""


from sys import stderr
from os.path import basename, dirname, realpath, isdir, isfile
from os import environ
import logging
import logging.config
import pathlib

from samestr.utils.utilities import collect_input_files
from samestr.utils.ooSubprocess import serialize, parallelize_async
from samestr.utils.file_mapping import spread_args_by_input_files, get_uniform_extension, \
    set_output_structure

from samestr.convert import sam2bam, concatenate_gene_files, bam2freq
from samestr.extract import ref2freq
from samestr.filter import filter_freqs
from samestr.merge import freq2freqs
from samestr.stats import aln2stats
from samestr.compare import compare
from samestr.summarize import summarize
from samestr.db import mp2db

from samestr.utils.parse_args import read_params
from samestr.utils.citations import citations


SAMESTR_DIR = dirname(realpath(__file__))
CONVERT_DIR = SAMESTR_DIR + '/convert/'
UTILS_DIR = SAMESTR_DIR + '/utils/'
environ['PATH'] += ':' + UTILS_DIR + ':' + CONVERT_DIR


def samestr(input_args):
    """Main function for SAMESTR."""
    accepted_extensions_dict = {
        'convert': ['.sam', '.sam.bz2'],
        'db': ['.fasta', '.fa', '.fna', '.fasta.bz2', '.fa.bz2', '.fna.bz2'],
        'extract': ['.fasta', '.fa', '.fna', '.fasta.gz', '.fa.gz', '.fna.gz'],
        'merge': ['.npy', '.npy.gz', '.npz'],
        'filter': ['.npy', '.npy.gz', '.npz'],
        'stats': ['.npy', '.npy.gz', '.npz'],
        'compare': ['.npy', '.npy.gz', '.npz'],
        'summarize': ['']
    }

    ## preprocess input/output files & extensions and map to commands
    ####
    accepted_extensions = accepted_extensions_dict[input_args['command']]
    if input_args['command'] == 'db':
        input_args['input_extension'] = get_uniform_extension(
            [input_args['mpa_markers']], accepted_extensions)

    elif input_args['command'] not in ('summarize', 'convert'):
        input_args['input_extension'] = get_uniform_extension(
            input_args['input_files'], accepted_extensions)

        # Count input files
        file_count = len(input_args['input_files'])
        LOG.debug('Number of input files: %s', file_count)

    # check make output dir
    if not isdir(input_args['output_dir']):
        pathlib.Path(input_args['output_dir']).mkdir(exist_ok=True, parents=True)

    input_species = input_args.get("species")

    ## process individual commands
    ####
    if input_args['command'] == 'convert':
        input_args['input_files'], input_args['input_extension'] = collect_input_files(
            input_args['input_dir'],
            accepted_extensions,
            recursive=input_args["recursive_input"]
        )
        
        # Spread args over files/file-pairs, Set output names and check/make their dir
        input_args['input_sequence_type'] = 'single'
        cmd_args = spread_args_by_input_files(input_args)
        cmd_args = set_output_structure(cmd_args)

        # Run: convert
        cmd_args = parallelize_async(sam2bam, cmd_args, input_args['nprocs'])
        cmd_args = parallelize_async(concatenate_gene_files, cmd_args,
                                 input_args['nprocs'])
        cmd_args = parallelize_async(bam2freq, cmd_args, input_args['nprocs'])

    elif input_args['command'] == 'db':

        # expand and generate db from metaphlan markers/pkl files
        mp2db(input_args)

    elif input_args['command'] == 'merge':

        species_file_dict = {}

        # group input files by species
        for file_path in input_args['input_files']:
            fn = basename(file_path)
            species = fn.split('.')[0]

            # append list if file has been merged before
            sample_names = file_path.replace(
                input_args['input_extension'], '.names.txt'
            )
            if isfile(sample_names):
                with open(sample_names, 'r', encoding="utf8") as s_n:
                    sample = s_n.read().strip().split('\n')
            else:
                sample = fn.split(
                    input_args['input_extension']
                )[0].replace(f'{species}.', '')

            # skip if not in selected species
            if input_species is not None and species not in input_species:
                continue

            species_file_dict.setdefault(species, []).append([sample, file_path])            

        cmd_args = [
            {
                "species": species,
                "input_files": files,
                "output_dir": input_args['output_dir'],
            }
            for species, files in species.items()
        ]

        cmd_args = parallelize_async(freq2freqs, cmd_args, input_args['nprocs'])

    elif input_args['command'] in ['filter', 'stats', 'compare']:

        # For each species: group freqs with resp names
        freqs = {
            basename(fn).split(input_args['input_extension'])[0]: [fn]
            for fn in input_args['input_files']
        }

        for name in input_args['input_names']:
            species = basename(name).split('.names.txt')[0]
            if species not in freqs:
                LOG.warning('Skipping %s. Found name file '
                            'but no SNV profile.', species)
            else:
                freqs[species].append(name)

        for species, freq in list(freqs.items()):
            if len(freq) != 2:
                LOG.warning('Skipping %s. Found SNV profile '
                            'but no name file.', species)
                freqs.pop(species)
            elif input_species is not None and species not in input_species:
                freqs.pop(species)

        # attach sample selection file
        if 'samples_select' in input_args:
            for i_s in input_args['samples_select']:
                species = basename(i_s).split('.select.txt')[0]
                if species not in freqs:
                    LOG.warning('Skipping %s. Found selection file '
                                'but no SNV profile.', species)
                else:
                    freqs[species].append(i_s)

        for species, freq in list(freqs.items()):
            if len(freq) > 3:
                LOG.warning('Skipping %s. Found more than one '
                            'sample selection file.', species)
                freqs.pop(species)
            elif len(freq) == 2:
                freq += [None]
            elif len(freq) != 3:
                LOG.error('Unexpected number of files (%s): %s.', len(freq), species)
                exit(0)  # <-- this is not really a zero-exit then, is it?

        # Spread args over species
        cmd_args = []
        ignore_args = {'input_files', 'input_names', 'input_select', 'species'}

        arg_template_d = {
            arg: value
            for arg, value in input_args.items()
            if arg not in ignore_args
        }

        for species, (input_file, input_name, input_select) in freqs.items():
            
            args_d = {
                "input_file": input_file,
                "input_name": input_name,
                "input_select": input_select,
                "species": species,
            }

            args_d.update(arg_template_d)

            cmd_args.append(args_d)
            
        if input_args['command'] == 'filter':
            LOG.info('Filtering files: %s', len(freqs))

            # Run: filter
            cmd_args = parallelize_async(filter_freqs, cmd_args, input_args['nprocs'])

        elif input_args['command'] == 'stats':
            LOG.info('Gathering statistics: %s', len(freqs))

            # Run: stats
            cmd_args = parallelize_async(aln2stats, cmd_args, input_args['nprocs'])

        elif input_args['command'] == 'compare':
            LOG.info('Comparing alignments: %s', len(freqs))

            # Run: compare
            cmd_args = parallelize_async(compare, cmd_args, input_args['nprocs'])

    elif input_args['command'] == 'summarize':
        cmd_args = serialize(summarize, [input_args])

    elif input_args['command'] == 'extract':
        cmd_args = serialize(ref2freq, [input_args])



if __name__ == "__main__":
    args = read_params()

    if args['citation'] is not None:
        print(citations[args['citation']])
        exit(0)

    logging.basicConfig(
    level=getattr(logging, args['verbosity']),
    stream=stderr,
    format='%(asctime)s | %(levelname)s | %(name)s | %(funcName)s | %(lineno)d | %(message)s'
    )
    LOG = logging.getLogger(__name__)

    samestr(args)
